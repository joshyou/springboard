{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Progress summary:**\n",
    "\n",
    "Tried logistic regression and random forests to predict success. Logistic regression predicted all attacks as successful; random forests did predict some failures but had low recall for failures.\n",
    "\n",
    "Also tried logistic regression, random forests, and SVM for predicting whether an attack results in any fatalities. Accuracy scores for all were 70-something percent (in dataset, 45% of attacks result in fatalities). Overfitting does not seem to be a problem right now, so adding more explanatory variables to boost accuracy might help.\n",
    "\n",
    "**to do/questions:**\n",
    "    \n",
    "how to improve recall for unsuccessful attacks (how to give greater weight to recall for unsuccessful attacks when tuning)\n",
    "\n",
    "how to run SVC faster to properly tune it\n",
    "\n",
    "replace success with fatality rate or another metric? improving recall just means trying to pin down the small proportion of attempted attacks that aren't successful. But when most attacks in the dataset are successful, identifying failures doesn't matter that much. In this context, identifying a failure is less important than identifying successes (while if it were the other way around, 90% failure and 10% success, improving recall for success would be very important)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122376 entries, 0 to 122375\n",
      "Data columns (total 24 columns):\n",
      "Unnamed: 0     122376 non-null int64\n",
      "iyear          122376 non-null int64\n",
      "imonth         122376 non-null int64\n",
      "region         122376 non-null int64\n",
      "crit1          122376 non-null int64\n",
      "crit2          122376 non-null int64\n",
      "crit3          122376 non-null int64\n",
      "success        122376 non-null int64\n",
      "suicide        122376 non-null int64\n",
      "attacktype1    122376 non-null float64\n",
      "attacktype2    3533 non-null float64\n",
      "attacktype3    214 non-null float64\n",
      "targtype1      122376 non-null float64\n",
      "targtype2      6685 non-null float64\n",
      "targtype3      703 non-null float64\n",
      "individual     122376 non-null int64\n",
      "weaptype1      122376 non-null float64\n",
      "weaptype2      8547 non-null float64\n",
      "weaptype3      1127 non-null float64\n",
      "weaptype4      63 non-null float64\n",
      "nkill          122376 non-null float64\n",
      "nwound         122376 non-null float64\n",
      "property       122376 non-null float64\n",
      "propextent     37549 non-null float64\n",
      "dtypes: float64(14), int64(10)\n",
      "memory usage: 22.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "explanatory_vars = ['region','crit1','crit2','crit3','suicide','attacktype1','targtype1','individual','weaptype1']\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(df[explanatory_vars].values, df['success'], random_state = 42, test_size = 0.2)\n",
    "\n",
    "Xtraining, Xholdout, ytraining, yholdout = train_test_split(Xtrain, ytrain, random_state = 42, test_size = 0.2)\n",
    "\n",
    "print(type(Xtrain), type(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#does cross-validation and computes average score for the 5 folds\n",
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold, random_state = 42).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y.iloc[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y.iloc[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using logistic regression to predict success:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899305413687\n"
     ]
    }
   ],
   "source": [
    "Log_clf = LogisticRegression()\n",
    "\n",
    "#ytrain = ytrain.reset_index()\n",
    "\n",
    "print(cv_score(Log_clf, Xtrain, ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17591     0]\n",
      " [ 1989     0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      1989\n",
      "          1       0.90      1.00      0.95     17591\n",
      "\n",
      "avg / total       0.81      0.90      0.85     19580\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "Log_clf.fit(Xtraining, ytraining)\n",
    "print(confusion_matrix(yholdout, Log_clf.predict(Xholdout), labels = [1,0]))\n",
    "print(classification_report(yholdout, Log_clf.predict(Xholdout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19580 19580\n"
     ]
    }
   ],
   "source": [
    "print(len(Log_clf.predict(Xholdout)), np.sum(Log_clf.predict(Xholdout)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression classifies every attack as a success. The accuracy score, and unweighted F1 score, are technically high but this doesn't seem very meaningful. Now I'll try regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[[17591     0]\n",
      " [ 1989     0]]\n",
      "0.1\n",
      "[[17591     0]\n",
      " [ 1989     0]]\n",
      "1\n",
      "[[17591     0]\n",
      " [ 1989     0]]\n",
      "10\n",
      "[[17591     0]\n",
      " [ 1989     0]]\n",
      "100\n",
      "[[17591     0]\n",
      " [ 1989     0]]\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "\n",
    "for c in Cs:\n",
    "    reg_clf = LogisticRegression(C = c)\n",
    "    reg_clf.fit(Xtraining, ytraining)\n",
    "    print(c)\n",
    "    print(confusion_matrix(yholdout, reg_clf.predict(Xholdout), labels = [1,0]))\n",
    "\n",
    "#for every regularization parameter, still predicts everything as success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier still classifies everything as a success. Not sure how to tune logistic regression to try to predict negatives.\n",
    "\n",
    "Next, random forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17427   164]\n",
      " [ 1722   267]]\n",
      "0.948666303756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "Rf_clf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "Rf_clf.fit(Xtraining, ytraining)\n",
    "\n",
    "print(confusion_matrix(yholdout, Rf_clf.predict(Xholdout),labels=[1,0]))\n",
    "\n",
    "print(f1_score(yholdout, Rf_clf.predict(Xholdout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.13      0.22      1989\n",
      "          1       0.91      0.99      0.95     17591\n",
      "\n",
      "avg / total       0.88      0.90      0.87     19580\n",
      "\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yholdout, Rf_clf.predict(Xholdout)))\n",
    "print(type(classification_report(yholdout, Rf_clf.predict(Xholdout))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest predicts some failures, but the recall is still very low (0.13) for unsuccessful attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_impurity_decrease': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "param_grid = {'max_depth':[3,5,10,20,100], 'min_impurity_decrease':[1e-7,1e-6,1e-5, 1e-4, 1e-3, 1e-2]}\n",
    "scorer = make_scorer(f1_score)\n",
    "Rf_clf = RandomForestClassifier()\n",
    "Rf_clf_cv = GridSearchCV(Rf_clf, param_grid, cv = 5, scoring = scorer)\n",
    "Rf_clf_cv.fit(Xtrain, ytrain)\n",
    "\n",
    "print(Rf_clf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.12      0.20      9858\n",
      "          1       0.91      0.99      0.95     88042\n",
      "\n",
      "avg / total       0.89      0.91      0.87     97900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rf_clf_tuned = RandomForestClassifier(max_depth = 10, min_impurity_decrease = 1e-6)\n",
    "\n",
    "Rf_clf_tuned.fit(Xtrain,ytrain)\n",
    "print(classification_report(ytrain, Rf_clf_tuned.predict(Xtrain)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning does not make much of a difference.\n",
    "\n",
    "Moving to fatality rate, which is closer to 50/50 which makes interpreting metrics easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.453046348957\n"
     ]
    }
   ],
   "source": [
    "df['fatal'] = df['nkill'] > 0\n",
    "print(df['fatal'].sum()/df['fatal'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738804902962\n"
     ]
    }
   ],
   "source": [
    "Xtrain_f, Xtest_f, ytrain_f, ytest_f = train_test_split(df[explanatory_vars].values, df['fatal'], random_state = 42, test_size = 0.2)\n",
    "\n",
    "Log_clf_f = LogisticRegression()\n",
    "\n",
    "print(cv_score(Log_clf_f, Xtrain_f, ytrain_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.81      0.77     53654\n",
      "       True       0.74      0.65      0.69     44246\n",
      "\n",
      "avg / total       0.74      0.74      0.74     97900\n",
      "\n",
      "0.73797752809\n"
     ]
    }
   ],
   "source": [
    "Log_clf_f = LogisticRegression()\n",
    "Log_clf_f.fit(Xtrain_f, ytrain_f)\n",
    "print(classification_report(ytrain_f, Log_clf_f.predict(Xtrain_f)))\n",
    "print(accuracy_score(ytrain_f, Log_clf_f.predict(Xtrain_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score on training data is approximately the same as average cross-validation score, so there is no overfitting even without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766884576098\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "Rf_clf_f = RandomForestClassifier()\n",
    "\n",
    "print(cv_score(Rf_clf_f, Xtrain_f, ytrain_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.78      0.79     53654\n",
      "       True       0.74      0.77      0.76     44246\n",
      "\n",
      "avg / total       0.78      0.78      0.78     97900\n",
      "\n",
      "0.775863125638\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytrain_f, Rf_clf_f.predict(Xtrain_f)))\n",
    "print(accuracy_score(ytrain_f, Rf_clf_f.predict(Xtrain_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average cross-validated score is only slightly worse than the accuracy on training data, so there is little overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 100, 'min_impurity_decrease': 1e-07}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth':[3,5,10,20,100], 'min_impurity_decrease':[1e-7,1e-6,1e-5, 1e-4, 1e-3, 1e-2]}\n",
    "scorer = make_scorer(f1_score)\n",
    "Rf_clf_f = RandomForestClassifier()\n",
    "Rf_clf_fcv = GridSearchCV(Rf_clf_f, param_grid, cv = 5, scoring = scorer)\n",
    "Rf_clf_fcv.fit(Xtrain_f, ytrain_f)\n",
    "\n",
    "print(Rf_clf_fcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76759959142\n"
     ]
    }
   ],
   "source": [
    "Rf_clf_f_tuned = RandomForestClassifier(max_depth = 100, min_impurity_decrease = 1e-07)\n",
    "\n",
    "Rf_clf_f_tuned.fit(Xtrain_f,ytrain_f)\n",
    "\n",
    "print(cv_score(Rf_clf_f_tuned, Xtrain_f, ytrain_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763258426966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "Sv_clf_f = SVC()\n",
    "\n",
    "Sv_clf_f.fit(Xtrain_f, ytrain_f)\n",
    "\n",
    "print(accuracy_score(ytrain_f, Sv_clf_f.predict(Xtrain_f)))\n",
    "#accuracy is 0.76326. This takes a long time (>10 minutes) to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "Sv_clf_f = SVC()\n",
    "\n",
    "#this takes forever...\n",
    "print(cv_score(Sv_clf_f, Xtrain_f, ytrain_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
