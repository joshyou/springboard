{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Progress summary:**\n",
    "\n",
    "\n",
    "Revisited data cleaning and turned weapon type, target type, attack type into binary variables. This is more meaningful because some attacks have multiple values for these categories (multiple weapons used, etc). Additionally, they need to be binarized for SVM to treat them correctly (https://www.quora.com/How-can-l-apply-an-SVM-for-categorical-data). However, doing this did not appear to improve performance. \n",
    "\n",
    "**to do/questions:**\n",
    "    \n",
    "how to run SVC faster - is using a smaller training set reasonable\n",
    "\n",
    "reporting and interpreting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#does cross-validation and computes average score for the 5 folds\n",
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold, random_state = 42).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y.iloc[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y.iloc[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned.csv')\n",
    "df['fatal'] = df['nkill'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "explanatory_vars = ['region','crit1','crit2','crit3','suicide','attacktype1','targtype1','individual','weaptype1', 'imonth']\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(df[explanatory_vars].values, df['success'], random_state = 42, test_size = 0.2)\n",
    "\n",
    "Xtraining, Xholdout, ytraining, yholdout = train_test_split(Xtrain, ytrain, random_state = 42, test_size = 0.2)\n",
    "\n",
    "print(type(Xtrain), type(ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using logistic regression to predict success:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899305413687\n"
     ]
    }
   ],
   "source": [
    "Log_clf = LogisticRegression()\n",
    "\n",
    "#ytrain = ytrain.reset_index()\n",
    "\n",
    "print(cv_score(Log_clf, Xtrain, ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17591     0]\n",
      " [ 1989     0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      1989\n",
      "          1       0.90      1.00      0.95     17591\n",
      "\n",
      "avg / total       0.81      0.90      0.85     19580\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Log_clf.fit(Xtraining, ytraining)\n",
    "print(confusion_matrix(yholdout, Log_clf.predict(Xholdout), labels = [1,0]))\n",
    "print(classification_report(yholdout, Log_clf.predict(Xholdout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19580 19580\n"
     ]
    }
   ],
   "source": [
    "print(len(Log_clf.predict(Xholdout)), np.sum(Log_clf.predict(Xholdout)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression classifies every attack as a success. The accuracy score, and unweighted F1 score, are technically high but this doesn't seem very meaningful. Now I'll try regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[[17591     0]\n",
      " [ 1989     0]]\n",
      "0.1\n",
      "[[17591     0]\n",
      " [ 1989     0]]\n",
      "1\n",
      "[[17591     0]\n",
      " [ 1989     0]]\n",
      "10\n",
      "[[17591     0]\n",
      " [ 1989     0]]\n",
      "100\n",
      "[[17591     0]\n",
      " [ 1989     0]]\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "\n",
    "for c in Cs:\n",
    "    reg_clf = LogisticRegression(C = c)\n",
    "    reg_clf.fit(Xtraining, ytraining)\n",
    "    print(c)\n",
    "    print(confusion_matrix(yholdout, reg_clf.predict(Xholdout), labels = [1,0]))\n",
    "\n",
    "#for every regularization parameter, still predicts everything as success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier still classifies everything as a success. Not sure how to tune logistic regression to try to predict negatives.\n",
    "\n",
    "Next, random forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17427   164]\n",
      " [ 1722   267]]\n",
      "0.948666303756\n"
     ]
    }
   ],
   "source": [
    "Rf_clf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "Rf_clf.fit(Xtraining, ytraining)\n",
    "\n",
    "print(confusion_matrix(yholdout, Rf_clf.predict(Xholdout),labels=[1,0]))\n",
    "\n",
    "print(f1_score(yholdout, Rf_clf.predict(Xholdout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.13      0.22      1989\n",
      "          1       0.91      0.99      0.95     17591\n",
      "\n",
      "avg / total       0.88      0.90      0.87     19580\n",
      "\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yholdout, Rf_clf.predict(Xholdout)))\n",
    "print(type(classification_report(yholdout, Rf_clf.predict(Xholdout))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest predicts some failures, but the recall is still very low (0.13) for unsuccessful attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_impurity_decrease': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth':[3,5,10,20,100], 'min_impurity_decrease':[1e-7,1e-6,1e-5, 1e-4, 1e-3, 1e-2]}\n",
    "scorer = make_scorer(f1_score)\n",
    "Rf_clf = RandomForestClassifier()\n",
    "Rf_clf_cv = GridSearchCV(Rf_clf, param_grid, cv = 5, scoring = scorer)\n",
    "Rf_clf_cv.fit(Xtrain, ytrain)\n",
    "\n",
    "print(Rf_clf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.12      0.20      9858\n",
      "          1       0.91      0.99      0.95     88042\n",
      "\n",
      "avg / total       0.89      0.91      0.87     97900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rf_clf_tuned = RandomForestClassifier(max_depth = 10, min_impurity_decrease = 1e-6)\n",
    "\n",
    "Rf_clf_tuned.fit(Xtrain,ytrain)\n",
    "print(classification_report(ytrain, Rf_clf_tuned.predict(Xtrain)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning does not make much of a difference.\n",
    "\n",
    "## Classifing fatality\n",
    "\n",
    "Moving to fatality rate, which is closer to 50/50 which makes interpreting metrics easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.453046348957\n"
     ]
    }
   ],
   "source": [
    "print(df['fatal'].sum()/df['fatal'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738764044944\n"
     ]
    }
   ],
   "source": [
    "Xtrain_f, Xtest_f, ytrain_f, ytest_f = train_test_split(df[explanatory_vars].values, df['fatal'], random_state = 42, test_size = 0.2)\n",
    "\n",
    "Log_clf_f = LogisticRegression()\n",
    "\n",
    "print(cv_score(Log_clf_f, Xtrain_f, ytrain_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average accuracy score of 0.7387 after cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.82      0.77     53654\n",
      "       True       0.74      0.64      0.69     44246\n",
      "\n",
      "avg / total       0.74      0.74      0.74     97900\n",
      "\n",
      "0.739039836568\n"
     ]
    }
   ],
   "source": [
    "Log_clf_f = LogisticRegression()\n",
    "Log_clf_f.fit(Xtrain_f, ytrain_f)\n",
    "print(classification_report(ytrain_f, Log_clf_f.predict(Xtrain_f)))\n",
    "print(accuracy_score(ytrain_f, Log_clf_f.predict(Xtrain_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score on training data (0.739) is approximately the same as average cross-validation score, so there is no overfitting even without regularization. F1-score is somewhat better for non-fatal attacks (0.77 vs 0.69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.760847803882\n"
     ]
    }
   ],
   "source": [
    "Rf_clf_f = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "print(cv_score(Rf_clf_f, Xtrain_f, ytrain_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.81      0.81     53654\n",
      "       True       0.77      0.78      0.77     44246\n",
      "\n",
      "avg / total       0.79      0.79      0.79     97900\n",
      "\n",
      "0.792042900919\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytrain_f, Rf_clf_f.predict(Xtrain_f)))\n",
    "print(accuracy_score(ytrain_f, Rf_clf_f.predict(Xtrain_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average cross-validated score (0.76) is only slightly worse than the accuracy on training data (0.792), so there is only a little overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 100, 'min_impurity_decrease': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth':[10,20,100,500,1000], 'min_impurity_decrease':[1e-9, 1e-8, 1e-7,1e-6,1e-5, 1e-4, 1e-3, 1e-2]}\n",
    "scorer = make_scorer(f1_score)\n",
    "Rf_clf_f = RandomForestClassifier()\n",
    "Rf_clf_fcv = GridSearchCV(Rf_clf_f, param_grid, cv = 5, scoring = scorer)\n",
    "Rf_clf_fcv.fit(Xtrain_f, ytrain_f)\n",
    "\n",
    "print(Rf_clf_fcv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best params: max_depth 100, min_impurity_decrease 1e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766894790603\n"
     ]
    }
   ],
   "source": [
    "Rf_clf_f_tuned = RandomForestClassifier(max_depth = 100, min_impurity_decrease = 1e-06)\n",
    "\n",
    "Rf_clf_f_tuned.fit(Xtrain_f,ytrain_f)\n",
    "\n",
    "print(cv_score(Rf_clf_f_tuned, Xtrain_f, ytrain_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score after tuning is 0.767, which is a very small improvement over the untuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763258426966\n"
     ]
    }
   ],
   "source": [
    "Sv_clf_f = SVC()\n",
    "\n",
    "Sv_clf_f.fit(Xtrain_f, ytrain_f)\n",
    "\n",
    "print(accuracy_score(ytrain_f, Sv_clf_f.predict(Xtrain_f)))\n",
    "#accuracy is 0.76326. This takes a long time (>10 minutes) to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "Sv_clf_f = SVC()\n",
    "\n",
    "#this takes forever...\n",
    "print(cv_score(Sv_clf_f, Xtrain_f, ytrain_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "potential variables to add: country, target subtype, number of perpetrators, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned.csv')\n",
    "df['fatal'] = df['nkill'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['region', 'crit1', 'crit2', 'crit3', 'suicide', 'individual', 'North America', 'Central America', 'South America', 'East Asia', 'SE Asia', 'South Asia', 'Central Asia', 'West Europe', 'East Europe', 'ME and North Africa', 'Sub-Saharan Africa', 'Biological', 'Chemical', 'Radiological', 'Nuclear', 'Firearms', 'Explosives', 'Fake Weapon', 'Incendiary', 'Melee', 'Vehicle', 'Sabotage Equipment', 'Assassination', 'Armed Assault', 'Bombing', 'Hijacking', 'Hostage (Barricade)', 'Kidnapping', 'Infrastructure', 'Business', 'Government', 'Police', 'Military', 'Abortion', 'Aviation', 'Diplomatic', 'Education', 'FoodWater', 'Media', 'Maritime', 'NGO', 'Private', 'Religious', 'Telecommunication', 'Terrorists', 'Tourists', 'Transportation', 'Utilities', 'Violent Parties']\n"
     ]
    }
   ],
   "source": [
    "explanatory_vars = cols[2:6] + [cols[7]] + [cols[14]] + cols[23:72]\n",
    "\n",
    "print(explanatory_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766016343207\n"
     ]
    }
   ],
   "source": [
    "Xtrain_f, Xtest_f, ytrain_f, ytest_f = train_test_split(df[explanatory_vars].values, df['fatal'], random_state = 42, test_size = 0.2)\n",
    "\n",
    "Log_clf_f = LogisticRegression()\n",
    "\n",
    "print(cv_score(Log_clf_f, Xtrain_f, ytrain_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.769397344229\n"
     ]
    }
   ],
   "source": [
    "Rf_clf_f = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "print(cv_score(Rf_clf_f, Xtrain_f, ytrain_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784841675179\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(ytrain_f, Rf_clf_f.predict(Xtrain_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain_f, Xtest_f, ytrain_f, ytest_f = train_test_split(df[explanatory_vars].values, df['fatal'], random_state = 42, test_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75841686642\n"
     ]
    }
   ],
   "source": [
    "Sv_clf_f = SVC(kernel = 'linear')\n",
    "\n",
    "Sv_clf_f.fit(Xtrain_f, ytrain_f)\n",
    "\n",
    "print(accuracy_score(ytrain_f, Sv_clf_f.predict(Xtrain_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on 30% of the data with a linear kernel, I get accuracy of 0.758 on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759070603617\n"
     ]
    }
   ],
   "source": [
    "Sv_clf_f = SVC()\n",
    "\n",
    "Sv_clf_f.fit(Xtrain_f, ytrain_f)\n",
    "\n",
    "print(accuracy_score(ytrain_f, Sv_clf_f.predict(Xtrain_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With rbf kernel (sklearn default), accuracy is 0.759 on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757463648466\n"
     ]
    }
   ],
   "source": [
    "Sv_clf_f = SVC(kernel = 'linear')\n",
    "print(cv_score(Sv_clf_f, Xtrain_f, ytrain_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validated score for a linear kernel is 0.7574, indicating low overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
